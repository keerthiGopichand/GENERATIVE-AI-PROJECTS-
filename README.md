
# E-commerce Retrieval Augmented generation Chatbot

## INTRODUCTION
This project is an E-commerce Chatbot built using a Retrieval-Augmented Generation (RAG) approach. RAG combines the power of information retrieval and generative language models, enabling the chatbot to provide accurate and context-aware responses based on extensive product-related information stored in a vector database. We used LangChain as the framework to manage the chatbot‚Äôs components and orchestrate the retrieval-generation flow efficiently.
## Model and Embeddings
The chatbot employs LLaMA3.1-8B, a large language model known for its ability to understand nuanced context and generate coherent responses. To enhance retrieval performance, the project leverages embeddings generated by HuggingFace's sentence-transformers/all-mpnet-base-v2 model. These embeddings encode semantic meaning, enabling the chatbot to retrieve relevant product data quickly based on user queries. The embeddings are stored and managed in AstraDB, which serves as a high-performance vector database.
## RAG with Chat History
To provide coherent, context-aware responses, the chatbot uses a history-aware RAG approach. By incorporating chat history into each interaction, the model can understand references to previous messages and maintain continuity across multiple turns. LangChain‚Äôs history management features make this process seamless by allowing stateful management of chat history for each user session.
## Dataset Handling Apporach
The dataset used in this project comprises product reviews sourced from Flipkart, an e-commerce platform. The dataset includes product titles, ratings, and detailed reviews, offering a comprehensive view of customer feedback across various products. The primary purpose of this dataset is to power the chatbot's retrieval capabilities, enabling it to reference real-world product sentiments, features, and customer experiences. Each review is stored as a Document object within LangChain, containing the review as content and the product name as metadata. The dataset is ingested into AstraDB as a vector store, enabling similarity searches that match user queries with relevant reviews, enhancing the chatbot's recommendations and responses.
## Frontend and Interaction
The frontend is a responsive web interface created using STRAMLITE, DJANGO, FLASK  designed to provide an intuitive chat experience. Users can interact with the chatbot to inquire about product details and receive personalized recommendations. The interface is styled with  featuring a modern gradient background and a structured chat box where user messages and bot responses are displayed in real-time.
## Handling Long Response Times with Redis and Celery
Given the model‚Äôs large size, generating responses with LLaMA 3.1-8b can occasionally exceed the default 1-minute server timeout limit. To manage this, we implemented Redis as a message broker and Celery for background task management. When a user submits a query, the chatbot triggers a Celery task that processes the response asynchronously, allowing the frontend to periodically poll for the response status. This method effectively prevents server timeout errors while ensuring users receive responses without interruptions
## Deployment on AWS EC2 
The chatbot is deployed on AWS EC2, providing a scalable and robust environment for running the model, handling user interactions, and managing retrievals from the database.

## Tech Stack üõ†Ô∏è
Language: Python
FrameWork: LangChain
Backend: Flask
Model: LLaMA 3.1-8b (Ollama), HuggingFace sentence-transformers
Database: AstraDB (vector storage for embeddings)
Message Queue: Redis
Task Management: Celery
Frontend: STREMLIT







## Installation

The Code is written in Python 3.10.15. If you don't have Python installed you can find it here. If you are using a lower version of Python you can upgrade using the pip package, ensuring you have the latest version of pip.
## Run locally 
## Step 1: Clone the repository to your local machine:
## Step 2: Navigate to the project directory:
## Step 3: Create a conda environment after opening the repository
## Step 4: Install the requirements
## Step 5: Set up environment variables:
- Create a .env file in the project directory.
- Define the necessary environment variables such as database connection strings, API keys, etc.
- Your.env file should should have these variables:
## Step 6: Download the Ollama API.
## Step 7: Go to a new terminal and after activating the environment. Start the ollama server.
## Step 8: Download the llama3.1-8B model.
## Step 9: Install Redis
## Step 10: Start the Redis Server(usually done on port 6379 by default).
## Step 11: Check if Redis is running. It should return PONG if everything is working fine.
## Step 12: Start the Celery Worker. In a new terminal window, activate the environment then run:
## Step 13: Run the Flask application. In another terminal, start your Flask application with Gunicorn
## Step 14 - Prediction application

# AWS DEPLOYMENT
Step 1: Push your entire code to github.
Step 2: Login to your AWS account Link.
Step 3: Launch your EC2 Instance.
Step 4: Configure your EC2 Instance.

## Step 5: Command for configuring EC2 Instance.
INFORMATION: sudo apt-get update and sudo apt update are used to update the package index on a Debian-based system like Ubuntu, but they are slightly different in terms of the tools they use and their functionality:

## Step 6: Connect your EC2 Instance and start typing the following commands

- Step 6.1: This command uses apt-get, the traditional package management tool.
- Step 6.2: This command uses apt, a newer, more user-friendly command-line interface for the APT package management system.
- 6.3: Install Nginx, Git and other tools
- Step 6.4: Install required tools.
- Step 6.5: Clone git repository.
- Step 6.5: Navigate to the project directory:
- Step 6.6: Navigate to the project directory:
- Step 6.7: Press insert and Mention .env variable then press esc for saving and write :wq for exit.
- Step 6.8: ### For checking the values of .env variables.
- Step 6.9: For installing python and pip here is a command
- Step 6.10: install the requirements.txt. The --break-system-packages flag in pip allows to override the externally-managed-environment error and install Python packages system-wide.
- Step 6.11: Test the Application with Gunicorn. Verify the app is working by visiting
- Step 6.12: Configure Nginx as a Reverse Proxy. Set up Nginx to forward requests to Gunicorn. Open the Nginx configuration file:
- Step 6.13: Update the Nginx configuration as follows:
# Save and close the file
- Step 6.14: Then restart Nginx:
- Step 6.15: Set Up Gunicorn as a Background Service. To keep Gunicorn running as a service, set up a systemd service file. Create a new service file:
- Step 6.16: Update the configuration as follows:
# Save and close the file
- Step 6.17: Start and enable the service:
## Step 7: Configure your inbound rule:
- Go inside the security
- Click on security group
- Configure your inbound rule with certain values
- Port 5000 0.0.0.0/0 for anywhere traffic TCP/IP protocol
- Port 8000 0.0.0.0/0 for anywhere traffic TCP/IP protocol
- Port 11434 0.0.0.0/0 for anywhere traffic TCP/IP protocol
## Step 8: Save it and now run your application.
## Step 9 - Run the Public Port of EC2 Instance
# conclusion 
- This E-commerce chatbot provides an intelligent, interactive shopping experience through a RAG approach that combines retrieval and generation, offering relevant product recommendations based on actual customer reviews.

- LLaMA 3.1's large language model and HuggingFace embeddings enable nuanced responses, enhancing user engagement with contextually aware conversations.

- Efficient response handling with Redis and Celery addresses the demands of a high-performing application, ensuring stable, responsive user experiences even with large LLMs.

- A fully scalable AWS EC2 deployment allows seamless integration into e-commerce platforms, offering robust infrastructure for high-traffic environments.

- This project showcases a powerful application of Large Language Models, pushing the boundaries of chatbot capabilities in the e-commerce domain.







    
